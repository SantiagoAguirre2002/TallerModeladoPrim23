{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2023\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Redes Neuronales para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales para clasificación toman como salida valores discretos, generalmente valores binarios (0, 1)\n",
    "- El principal cambio que debemos hacer para clasificación es cambiar la salida de la red neuronal. Se le pone una función de activación no lineal a la salida, generalmente se usa la función Sigmoidal. \n",
    "- Como función de costo se usa el Cross Entropy en lugar de la Suma de Residuales\n",
    "- Si tenemos una salida multiclase, se debe usar la función Softmax en lugar de la sigmoidal\n",
    "\n",
    "**Entonces... ¿qué pasaría si tengo una red neuronal con sólo una capa, donde la función de activación es sigmoidal? sería lo mismo que aplicar una regresión logística**\n",
    "\n",
    "Red neuronal con una capa con función de activación sigmoidal = Regresión logística\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://deeplearningmath.org/images/shallow_NN.png\" width=\"450px\" height=\"280px\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo para salida binaria**\n",
    "\n",
    "Queremos predecir si una persona va a tener diabetes o no (Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "desc = data.describe()\n",
    "info = data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar datos para train y test\n",
    "X = data.iloc[:,0:8]\n",
    "Y = np.ravel(data['Outcome'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.3613\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9447 - accuracy: 0.3743\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.3836\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.8933 - accuracy: 0.3855\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8708 - accuracy: 0.4041\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8492 - accuracy: 0.4209\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 484us/step - loss: 0.8285 - accuracy: 0.4320\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8095 - accuracy: 0.4451\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7919 - accuracy: 0.4507\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7754 - accuracy: 0.4693\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 861us/step - loss: 0.7599 - accuracy: 0.4823\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.5047\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7314 - accuracy: 0.5251\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.5382\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.5493\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5549\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5680\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 746us/step - loss: 0.6739 - accuracy: 0.5866\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6052\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6220\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6350\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6443\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6592\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.6685\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.6183 - accuracy: 0.6741\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6816\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6853\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6890\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7002\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7058\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7058\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 615us/step - loss: 0.5805 - accuracy: 0.7114\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7095\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 201us/step - loss: 0.5718 - accuracy: 0.7244\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7244\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 934us/step - loss: 0.5644 - accuracy: 0.7281\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7300\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7281\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7281\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.7318\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7393\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5450 - accuracy: 0.7393\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7393\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7393\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 974us/step - loss: 0.5369 - accuracy: 0.7374\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7449\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7430\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7467\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7505\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7505\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7486\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 857us/step - loss: 0.5213 - accuracy: 0.7505\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7561\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7579\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7579\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.5145 - accuracy: 0.7561\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7579\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7579\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7579\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 90us/step - loss: 0.5084 - accuracy: 0.7579\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7635\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 954us/step - loss: 0.5056 - accuracy: 0.7635\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7579\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7579\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7561\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7598\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4996 - accuracy: 0.7616\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 926us/step - loss: 0.4987 - accuracy: 0.7616\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 501us/step - loss: 0.4976 - accuracy: 0.7616\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7635\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 488us/step - loss: 0.4954 - accuracy: 0.7635\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4945 - accuracy: 0.7616\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 736us/step - loss: 0.4934 - accuracy: 0.7616\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7616\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7616\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7635\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7635\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7635\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7654\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4872 - accuracy: 0.7654\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7654\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 538us/step - loss: 0.4858 - accuracy: 0.7654\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7672\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7672\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7672\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 599us/step - loss: 0.4829 - accuracy: 0.7691\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7691\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 910us/step - loss: 0.4817 - accuracy: 0.7728\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7728\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 480us/step - loss: 0.4805 - accuracy: 0.7747\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7765\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7765\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4787 - accuracy: 0.7765\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7765\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 701us/step - loss: 0.4776 - accuracy: 0.7784\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7803\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4766 - accuracy: 0.7803\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4761 - accuracy: 0.7784\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 484us/step - loss: 0.4756 - accuracy: 0.7803\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7821\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7840\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7840\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7840\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7840\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7840\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4724 - accuracy: 0.7840\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7840\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 701us/step - loss: 0.4717 - accuracy: 0.7840\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4713 - accuracy: 0.7840\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 369us/step - loss: 0.4709 - accuracy: 0.7840\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4706 - accuracy: 0.7840\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 625us/step - loss: 0.4701 - accuracy: 0.7840\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7840\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 757us/step - loss: 0.4694 - accuracy: 0.7840\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7840\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7840\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7858\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7858\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4677 - accuracy: 0.7858\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7877\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 559us/step - loss: 0.4670 - accuracy: 0.7896\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7914\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7914\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7914\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7933\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7933\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7933\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 973us/step - loss: 0.4651 - accuracy: 0.7952\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4649 - accuracy: 0.7952\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 588us/step - loss: 0.4646 - accuracy: 0.7952\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7952\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7952\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4640 - accuracy: 0.7952\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7952\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7933\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7952\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7952\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7933\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 802us/step - loss: 0.4626 - accuracy: 0.7933\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 796us/step - loss: 0.4624 - accuracy: 0.7933\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7933\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 23us/step - loss: 0.4619 - accuracy: 0.7933\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7933\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7933\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7933\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7933\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7933\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7933\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7933\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7914\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7914\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4601 - accuracy: 0.7914\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7914\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 698us/step - loss: 0.4597 - accuracy: 0.7914\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4596 - accuracy: 0.7914\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 674us/step - loss: 0.4595 - accuracy: 0.7914\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4593 - accuracy: 0.7914\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7933\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7914\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 977us/step - loss: 0.4588 - accuracy: 0.7933\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7933\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7933\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 901us/step - loss: 0.4584 - accuracy: 0.7952\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7952\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7952\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7952\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4578 - accuracy: 0.7952\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7952\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7952\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7952\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4574 - accuracy: 0.7952\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7952\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 702us/step - loss: 0.4571 - accuracy: 0.7952\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7933\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7933\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7952\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4566 - accuracy: 0.7933\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7952\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7952\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4563 - accuracy: 0.7952\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 721us/step - loss: 0.4562 - accuracy: 0.7952\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7952\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7952\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4559 - accuracy: 0.7952\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 875us/step - loss: 0.4558 - accuracy: 0.7933\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 603us/step - loss: 0.4557 - accuracy: 0.7933\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 980us/step - loss: 0.4556 - accuracy: 0.7933\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7914\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7914\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4553 - accuracy: 0.7914\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7933\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 701us/step - loss: 0.4551 - accuracy: 0.7914\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4551 - accuracy: 0.7933\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 526us/step - loss: 0.4550 - accuracy: 0.7933\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7933\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7933\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7933\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7933\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7933\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "#Construir red neuronal\n",
    "from keras.models import Sequential #paso x paso\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='tanh', input_shape=(8,))) #se puede cambiar la función de activación\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser \"sigmoidal\" para problemas binomiales (0 y 1)\n",
    "\n",
    "# Configuración del optimizador\n",
    "model.compile(loss='binary_crossentropy',#función de costo\n",
    "              optimizer='sgd',#gradiente descendente\n",
    "              metrics=['accuracy'])#solo en clasificación es accuracy, mientras más positivo, mejor\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "model_history=model.fit(X_train, Y_train,epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy function'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ver el performance del modelo en el entrenamiento (accuracy)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 807us/step\n",
      "8/8 [==============================] - 0s 828us/step\n"
     ]
    }
   ],
   "source": [
    "#Usar el modelo para predecir\n",
    "x_nueva_persona= [6,45,242,2452]# lo metemos en el model predict\n",
    "Y_pred = model.predict(X_test) #predecir en términos de decimales\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\") #en términos de 1 y 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24473323],\n",
       "       [0.15233536],\n",
       "       [0.1326924 ],\n",
       "       [0.172815  ],\n",
       "       [0.5218854 ],\n",
       "       [0.4247325 ],\n",
       "       [0.0512966 ],\n",
       "       [0.6081912 ],\n",
       "       [0.57781893],\n",
       "       [0.76543915],\n",
       "       [0.20744245],\n",
       "       [0.82452303],\n",
       "       [0.3812879 ],\n",
       "       [0.32111782],\n",
       "       [0.10205744],\n",
       "       [0.43736362],\n",
       "       [0.12342057],\n",
       "       [0.08566181],\n",
       "       [0.87936985],\n",
       "       [0.6498193 ],\n",
       "       [0.1825951 ],\n",
       "       [0.06546394],\n",
       "       [0.43826944],\n",
       "       [0.09101782],\n",
       "       [0.5689663 ],\n",
       "       [0.8398418 ],\n",
       "       [0.11571562],\n",
       "       [0.05826442],\n",
       "       [0.2579674 ],\n",
       "       [0.10247927],\n",
       "       [0.80046904],\n",
       "       [0.78391814],\n",
       "       [0.7943693 ],\n",
       "       [0.838156  ],\n",
       "       [0.605633  ],\n",
       "       [0.73739344],\n",
       "       [0.7011808 ],\n",
       "       [0.2668799 ],\n",
       "       [0.4481573 ],\n",
       "       [0.68253314],\n",
       "       [0.08372971],\n",
       "       [0.54545534],\n",
       "       [0.5383564 ],\n",
       "       [0.33067724],\n",
       "       [0.06649006],\n",
       "       [0.61601096],\n",
       "       [0.6127112 ],\n",
       "       [0.18952581],\n",
       "       [0.3745422 ],\n",
       "       [0.81655985],\n",
       "       [0.06961972],\n",
       "       [0.6461396 ],\n",
       "       [0.79882765],\n",
       "       [0.27026227],\n",
       "       [0.11622537],\n",
       "       [0.06209708],\n",
       "       [0.7717048 ],\n",
       "       [0.0656769 ],\n",
       "       [0.48069662],\n",
       "       [0.78788894],\n",
       "       [0.75067514],\n",
       "       [0.33655748],\n",
       "       [0.3337243 ],\n",
       "       [0.20032734],\n",
       "       [0.06995218],\n",
       "       [0.6060653 ],\n",
       "       [0.07137346],\n",
       "       [0.75068617],\n",
       "       [0.0677298 ],\n",
       "       [0.79268646],\n",
       "       [0.7219286 ],\n",
       "       [0.06335211],\n",
       "       [0.13717169],\n",
       "       [0.09126486],\n",
       "       [0.11168179],\n",
       "       [0.48517913],\n",
       "       [0.18858348],\n",
       "       [0.14147024],\n",
       "       [0.12167551],\n",
       "       [0.24325007],\n",
       "       [0.7228643 ],\n",
       "       [0.12715434],\n",
       "       [0.07000018],\n",
       "       [0.42447302],\n",
       "       [0.2909669 ],\n",
       "       [0.8147154 ],\n",
       "       [0.845947  ],\n",
       "       [0.34313554],\n",
       "       [0.09877932],\n",
       "       [0.09723476],\n",
       "       [0.07370646],\n",
       "       [0.22624199],\n",
       "       [0.06426273],\n",
       "       [0.41205665],\n",
       "       [0.5615855 ],\n",
       "       [0.67986476],\n",
       "       [0.32183725],\n",
       "       [0.12613122],\n",
       "       [0.7192223 ],\n",
       "       [0.08566093],\n",
       "       [0.65268666],\n",
       "       [0.05874763],\n",
       "       [0.79313195],\n",
       "       [0.5718677 ],\n",
       "       [0.7372566 ],\n",
       "       [0.20112246],\n",
       "       [0.27073827],\n",
       "       [0.740853  ],\n",
       "       [0.16255806],\n",
       "       [0.5800887 ],\n",
       "       [0.10504974],\n",
       "       [0.40495643],\n",
       "       [0.07966089],\n",
       "       [0.73588264],\n",
       "       [0.15772316],\n",
       "       [0.32910183],\n",
       "       [0.7678914 ],\n",
       "       [0.22196569],\n",
       "       [0.09380089],\n",
       "       [0.42776117],\n",
       "       [0.08610019],\n",
       "       [0.25907785],\n",
       "       [0.19783355],\n",
       "       [0.11568238],\n",
       "       [0.2512351 ],\n",
       "       [0.35843626],\n",
       "       [0.1022153 ],\n",
       "       [0.8338271 ],\n",
       "       [0.87262017],\n",
       "       [0.69731116],\n",
       "       [0.75968206],\n",
       "       [0.8391471 ],\n",
       "       [0.10226944],\n",
       "       [0.41226834],\n",
       "       [0.79383004],\n",
       "       [0.12068821],\n",
       "       [0.1720537 ],\n",
       "       [0.7790653 ],\n",
       "       [0.7742336 ],\n",
       "       [0.04754531],\n",
       "       [0.08763633],\n",
       "       [0.0751413 ],\n",
       "       [0.19986163],\n",
       "       [0.57335573],\n",
       "       [0.12925558],\n",
       "       [0.2575379 ],\n",
       "       [0.16479202],\n",
       "       [0.06296095],\n",
       "       [0.3999861 ],\n",
       "       [0.75919604],\n",
       "       [0.17512731],\n",
       "       [0.4154339 ],\n",
       "       [0.2820664 ],\n",
       "       [0.19126949],\n",
       "       [0.06515617],\n",
       "       [0.5218398 ],\n",
       "       [0.3467878 ],\n",
       "       [0.6119292 ],\n",
       "       [0.74335515],\n",
       "       [0.1370666 ],\n",
       "       [0.4817045 ],\n",
       "       [0.6583599 ],\n",
       "       [0.16143902],\n",
       "       [0.06028382],\n",
       "       [0.1255872 ],\n",
       "       [0.8867962 ],\n",
       "       [0.05864821],\n",
       "       [0.28685045],\n",
       "       [0.7769085 ],\n",
       "       [0.67927986],\n",
       "       [0.65948635],\n",
       "       [0.18531743],\n",
       "       [0.32423934],\n",
       "       [0.77321994],\n",
       "       [0.71212333],\n",
       "       [0.09098618],\n",
       "       [0.24244222],\n",
       "       [0.24671488],\n",
       "       [0.19841523],\n",
       "       [0.39735508],\n",
       "       [0.4507385 ],\n",
       "       [0.6254461 ],\n",
       "       [0.3400116 ],\n",
       "       [0.7735411 ],\n",
       "       [0.6592178 ],\n",
       "       [0.09066507],\n",
       "       [0.06211178],\n",
       "       [0.11297271],\n",
       "       [0.79304296],\n",
       "       [0.41086552],\n",
       "       [0.09618212],\n",
       "       [0.10012893],\n",
       "       [0.77086264],\n",
       "       [0.24907917],\n",
       "       [0.07313164],\n",
       "       [0.06588891],\n",
       "       [0.05010157],\n",
       "       [0.07992816],\n",
       "       [0.26879108],\n",
       "       [0.7340556 ],\n",
       "       [0.16245376],\n",
       "       [0.08908395],\n",
       "       [0.30923748],\n",
       "       [0.38231844],\n",
       "       [0.75232965],\n",
       "       [0.08898386],\n",
       "       [0.11544537],\n",
       "       [0.20090713],\n",
       "       [0.8365163 ],\n",
       "       [0.68443096],\n",
       "       [0.27904466],\n",
       "       [0.19579548],\n",
       "       [0.13442732],\n",
       "       [0.132357  ],\n",
       "       [0.7158129 ],\n",
       "       [0.08898   ],\n",
       "       [0.74293983],\n",
       "       [0.3388695 ],\n",
       "       [0.34327522],\n",
       "       [0.85625255],\n",
       "       [0.6629226 ],\n",
       "       [0.10176762],\n",
       "       [0.09447633],\n",
       "       [0.128437  ],\n",
       "       [0.10397761],\n",
       "       [0.6872036 ],\n",
       "       [0.30213854],\n",
       "       [0.29075694],\n",
       "       [0.33016136],\n",
       "       [0.14907557],\n",
       "       [0.10428423]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 655us/step\n",
      "17/17 [==============================] - 0s 677us/step\n",
      "17/17 [==============================] - 0s 721us/step\n",
      "8/8 [==============================] - 0s 610us/step\n",
      "8/8 [==============================] - 0s 855us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.793 \t 0.755 \t 0.606\n",
      "  Test \t 0.745 \t 0.633 \t 0.625\n"
     ]
    }
   ],
   "source": [
    "#métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "\n",
    "#métricas en el train\n",
    "accu_train = accuracy_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "prec_train = precision_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "reca_train = recall_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "\n",
    "#métricas en el test\n",
    "accu_test = accuracy_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La más importante es **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Multiclase**\n",
    "\n",
    "- Aunque las salidas de la red neuronal están limitadas a un rango de valores entre 0 y 1, no se garantiza que la suma de estos sea igual a 1\n",
    "- Transformar las salidas para que puedan ser usadas como probabilidades ayuda mucho a la interpretabilidad de las predicciones\n",
    "- Transformación Softmax\n",
    "\n",
    "$$\\hat{p}_{l,i}^{*} = \\frac{e^{\\hat{y}_{l,i}}}{\\sum{e^{\\hat{y}_{l,i}}}}$$\n",
    "\n",
    "- $\\hat{y}_{1}=0.25$, $\\hat{y}_{2}=0.76$, $\\hat{y}_{3}=0.1$\n",
    "\n",
    "- $\\hat{p}_{1}=0.3099$, $\\hat{p}_{2}=0.4717$, $\\hat{p}_{3}=0.2184$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adam\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y #tres tipos de flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la variable target a dummies para poderla trabajar en la red neuronal\n",
    "dummy_y = np_utils.to_categorical(Y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatob\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 155ms/step - loss: 3.9565 - accuracy: 0.3083 - val_loss: 3.1532 - val_accuracy: 0.3667\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0019 - accuracy: 0.3250 - val_loss: 0.9880 - val_accuracy: 0.6000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.9990 - accuracy: 0.5583 - val_loss: 1.1282 - val_accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.1133 - accuracy: 0.3333 - val_loss: 1.1053 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0786 - accuracy: 0.3500 - val_loss: 0.8495 - val_accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8885 - accuracy: 0.6333 - val_loss: 0.7567 - val_accuracy: 0.7000\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7777 - accuracy: 0.6583 - val_loss: 0.7438 - val_accuracy: 0.7000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7734 - accuracy: 0.6833 - val_loss: 0.6785 - val_accuracy: 0.7000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7093 - accuracy: 0.6667 - val_loss: 0.6188 - val_accuracy: 0.7000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6492 - accuracy: 0.6583 - val_loss: 0.5908 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6091 - accuracy: 0.8333 - val_loss: 0.5718 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5758 - accuracy: 0.9333 - val_loss: 0.5301 - val_accuracy: 0.7000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5544 - accuracy: 0.6917 - val_loss: 0.5043 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5195 - accuracy: 0.8333 - val_loss: 0.4838 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4979 - accuracy: 0.8583 - val_loss: 0.4613 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4829 - accuracy: 0.7917 - val_loss: 0.4464 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4702 - accuracy: 0.7417 - val_loss: 0.4297 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4562 - accuracy: 0.7750 - val_loss: 0.4190 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4397 - accuracy: 0.9083 - val_loss: 0.4059 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.3982 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4217 - accuracy: 0.7833 - val_loss: 0.4074 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4212 - accuracy: 0.9667 - val_loss: 0.3895 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3994 - accuracy: 0.9500 - val_loss: 0.3872 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4092 - accuracy: 0.7583 - val_loss: 0.3720 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3848 - accuracy: 0.9750 - val_loss: 0.3751 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3844 - accuracy: 0.9500 - val_loss: 0.3510 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3720 - accuracy: 0.8583 - val_loss: 0.3412 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3578 - accuracy: 0.9583 - val_loss: 0.3586 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3714 - accuracy: 0.9583 - val_loss: 0.3256 - val_accuracy: 0.8667\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3489 - accuracy: 0.9167 - val_loss: 0.3277 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3427 - accuracy: 0.9750 - val_loss: 0.3476 - val_accuracy: 0.9667\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3563 - accuracy: 0.9333 - val_loss: 0.3128 - val_accuracy: 0.8667\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3302 - accuracy: 0.9250 - val_loss: 0.3052 - val_accuracy: 0.9667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3223 - accuracy: 0.9333 - val_loss: 0.3042 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3180 - accuracy: 0.9667 - val_loss: 0.2947 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3103 - accuracy: 0.9500 - val_loss: 0.2896 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3052 - accuracy: 0.9500 - val_loss: 0.2819 - val_accuracy: 0.9667\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3016 - accuracy: 0.9417 - val_loss: 0.2870 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3119 - accuracy: 0.9667 - val_loss: 0.2903 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3175 - accuracy: 0.8833 - val_loss: 0.2635 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2836 - accuracy: 0.9583 - val_loss: 0.3290 - val_accuracy: 0.9000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3433 - accuracy: 0.9250 - val_loss: 0.3076 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3268 - accuracy: 0.8583 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2700 - accuracy: 0.9667 - val_loss: 0.3080 - val_accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3136 - accuracy: 0.9333 - val_loss: 0.3715 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4002 - accuracy: 0.7500 - val_loss: 0.2455 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2556 - accuracy: 0.9667 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3638 - accuracy: 0.8333 - val_loss: 0.4170 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4350 - accuracy: 0.7417 - val_loss: 0.2455 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2849 - accuracy: 0.9417 - val_loss: 0.2691 - val_accuracy: 0.9667\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2837 - accuracy: 0.9333 - val_loss: 0.2673 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2771 - accuracy: 0.9167 - val_loss: 0.2566 - val_accuracy: 0.9667\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2761 - accuracy: 0.9500 - val_loss: 0.2253 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2478 - accuracy: 0.9417 - val_loss: 0.2226 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2497 - accuracy: 0.9500 - val_loss: 0.2180 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2395 - accuracy: 0.9417 - val_loss: 0.2210 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2412 - accuracy: 0.9500 - val_loss: 0.2171 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2388 - accuracy: 0.9667 - val_loss: 0.2569 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2742 - accuracy: 0.9000 - val_loss: 0.2060 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2271 - accuracy: 0.9500 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2229 - accuracy: 0.9583 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2224 - accuracy: 0.9500 - val_loss: 0.2144 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2268 - accuracy: 0.9667 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2171 - accuracy: 0.9583 - val_loss: 0.1943 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2136 - accuracy: 0.9583 - val_loss: 0.2034 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2301 - accuracy: 0.9500 - val_loss: 0.1894 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2102 - accuracy: 0.9583 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2086 - accuracy: 0.9583 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2069 - accuracy: 0.9750 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2067 - accuracy: 0.9583 - val_loss: 0.1893 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2043 - accuracy: 0.9500 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2072 - accuracy: 0.9667 - val_loss: 0.1818 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2004 - accuracy: 0.9583 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2098 - accuracy: 0.9667 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1999 - accuracy: 0.9583 - val_loss: 0.1954 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2109 - accuracy: 0.9500 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1944 - accuracy: 0.9750 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1953 - accuracy: 0.9750 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1941 - accuracy: 0.9750 - val_loss: 0.1692 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1908 - accuracy: 0.9667 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1871 - accuracy: 0.9583 - val_loss: 0.2028 - val_accuracy: 0.8667\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2147 - accuracy: 0.9500 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2039 - accuracy: 0.9500 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1924 - accuracy: 0.9583 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1817 - accuracy: 0.9750 - val_loss: 0.2736 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2796 - accuracy: 0.8750 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2081 - accuracy: 0.9500 - val_loss: 0.1684 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1722 - accuracy: 0.9583 - val_loss: 0.2673 - val_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2676 - accuracy: 0.8917 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2047 - accuracy: 0.9417 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1750 - accuracy: 0.9667 - val_loss: 0.1859 - val_accuracy: 0.9667\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2032 - accuracy: 0.9417 - val_loss: 0.1562 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1761 - accuracy: 0.9750 - val_loss: 0.1557 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1762 - accuracy: 0.9750 - val_loss: 0.1780 - val_accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1938 - accuracy: 0.9500 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1787 - accuracy: 0.9667 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1708 - accuracy: 0.9750 - val_loss: 0.1816 - val_accuracy: 0.9667\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1843 - accuracy: 0.9583 - val_loss: 0.2067 - val_accuracy: 0.9333\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2141 - accuracy: 0.9500 - val_loss: 0.1773 - val_accuracy: 0.9667\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1919 - accuracy: 0.9500 - val_loss: 0.1852 - val_accuracy: 0.9667\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1943 - accuracy: 0.9500 - val_loss: 0.1984 - val_accuracy: 0.9333\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2057 - accuracy: 0.9417 - val_loss: 0.1763 - val_accuracy: 0.9667\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2080 - accuracy: 0.9333 - val_loss: 0.2504 - val_accuracy: 0.9000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2894 - accuracy: 0.8917 - val_loss: 0.1553 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1956 - accuracy: 0.9417 - val_loss: 0.1722 - val_accuracy: 0.9667\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1922 - accuracy: 0.9500 - val_loss: 0.1961 - val_accuracy: 0.9333\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1946 - accuracy: 0.9667 - val_loss: 0.2046 - val_accuracy: 0.8667\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2062 - accuracy: 0.9417 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2040 - accuracy: 0.9417 - val_loss: 0.1977 - val_accuracy: 0.9333\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2085 - accuracy: 0.9250 - val_loss: 0.1795 - val_accuracy: 0.9667\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1897 - accuracy: 0.9417 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1530 - accuracy: 0.9750 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1651 - accuracy: 0.9500 - val_loss: 0.1691 - val_accuracy: 0.9667\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1814 - accuracy: 0.9500 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1563 - accuracy: 0.9667 - val_loss: 0.1431 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1540 - accuracy: 0.9750 - val_loss: 0.1827 - val_accuracy: 0.9333\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1935 - accuracy: 0.9417 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1530 - accuracy: 0.9500 - val_loss: 0.1481 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1612 - accuracy: 0.9667 - val_loss: 0.1373 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1485 - accuracy: 0.9750 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1501 - accuracy: 0.9750 - val_loss: 0.1377 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1484 - accuracy: 0.9750 - val_loss: 0.1401 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1524 - accuracy: 0.9667 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1566 - accuracy: 0.9667 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1445 - accuracy: 0.9750 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1531 - accuracy: 0.9583 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1541 - accuracy: 0.9667 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1517 - accuracy: 0.9583 - val_loss: 0.1415 - val_accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1545 - accuracy: 0.9500 - val_loss: 0.1341 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1592 - accuracy: 0.9500 - val_loss: 0.1982 - val_accuracy: 0.8667\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2113 - accuracy: 0.9333 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1608 - accuracy: 0.9583 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1605 - accuracy: 0.9583 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1513 - accuracy: 0.9667 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1418 - accuracy: 0.9833 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1384 - accuracy: 0.9750 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1384 - accuracy: 0.9833 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1455 - accuracy: 0.9583 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1384 - accuracy: 0.9750 - val_loss: 0.1213 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1360 - accuracy: 0.9750 - val_loss: 0.1241 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1373 - accuracy: 0.9750 - val_loss: 0.1250 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1369 - accuracy: 0.9750 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1416 - accuracy: 0.9667 - val_loss: 0.1363 - val_accuracy: 0.9667\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1481 - accuracy: 0.9667 - val_loss: 0.1427 - val_accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1521 - accuracy: 0.9583 - val_loss: 0.1360 - val_accuracy: 0.9667\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1500 - accuracy: 0.9583 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1427 - accuracy: 0.9750 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1414 - accuracy: 0.9750 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1264 - accuracy: 0.9833 - val_loss: 0.1858 - val_accuracy: 0.9333\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1940 - accuracy: 0.9583 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1463 - accuracy: 0.9667 - val_loss: 0.1359 - val_accuracy: 0.9667\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1442 - accuracy: 0.9667 - val_loss: 0.1838 - val_accuracy: 0.9333\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1854 - accuracy: 0.9500 - val_loss: 0.1585 - val_accuracy: 0.9667\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1755 - accuracy: 0.9500 - val_loss: 0.1527 - val_accuracy: 0.9333\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1825 - accuracy: 0.9250 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1448 - accuracy: 0.9750 - val_loss: 0.1838 - val_accuracy: 0.8667\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1823 - accuracy: 0.9500 - val_loss: 0.1405 - val_accuracy: 0.9667\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1650 - accuracy: 0.9417 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1404 - accuracy: 0.9750 - val_loss: 0.1093 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1380 - accuracy: 0.9583 - val_loss: 0.1183 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.1440 - val_accuracy: 0.9667\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1540 - accuracy: 0.9667 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1428 - accuracy: 0.9833 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.1282 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1402 - accuracy: 0.9833 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1344 - accuracy: 0.9750 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1328 - accuracy: 0.9750 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1235 - accuracy: 0.9750 - val_loss: 0.1306 - val_accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1418 - accuracy: 0.9583 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1213 - accuracy: 0.9750 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1297 - accuracy: 0.9833 - val_loss: 0.1238 - val_accuracy: 0.9667\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1386 - accuracy: 0.9583 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1329 - accuracy: 0.9667 - val_loss: 0.1131 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1337 - accuracy: 0.9667 - val_loss: 0.1112 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1210 - accuracy: 0.9667 - val_loss: 0.1198 - val_accuracy: 0.9667\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1308 - accuracy: 0.9583 - val_loss: 0.1171 - val_accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1409 - accuracy: 0.9500 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.1030 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1174 - accuracy: 0.9750 - val_loss: 0.1101 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1225 - accuracy: 0.9667 - val_loss: 0.1063 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1180 - accuracy: 0.9833 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1215 - accuracy: 0.9833 - val_loss: 0.1055 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1185 - accuracy: 0.9750 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1186 - accuracy: 0.9833 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1183 - accuracy: 0.9750 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 0.9833 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1164 - accuracy: 0.9833 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1165 - accuracy: 0.9750 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1257 - accuracy: 0.9583 - val_loss: 0.1171 - val_accuracy: 0.9667\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1397 - accuracy: 0.9500 - val_loss: 0.1048 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 0.9833 - val_loss: 0.1730 - val_accuracy: 0.9333\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1814 - accuracy: 0.9583 - val_loss: 0.1157 - val_accuracy: 0.9667\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1265 - accuracy: 0.9667 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1181 - accuracy: 0.9667 - val_loss: 0.1187 - val_accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1304 - accuracy: 0.9667 - val_loss: 0.0994 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1158 - accuracy: 0.9750 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1141 - accuracy: 0.9667 - val_loss: 0.1021 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Construcción de la red neuronal\n",
    "\n",
    "# neural network structure\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Gradiente descendente\n",
    "learning_rate=0.1\n",
    "epochs = 200\n",
    "momentum = 0.8\n",
    "decay_rate = learning_rate/epochs\n",
    "sgd = SGD(lr=learning_rate, decay=decay_rate, momentum=momentum)\n",
    "\n",
    "# configuracion del optimizador\n",
    "model.compile(loss='categorical_crossentropy',#funcion de costo\n",
    "              optimizer=sgd,#gradiente descendente\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# entrenamiento de la red neuronal\n",
    "#history = model.fit(X, dummy_y,epochs=200, batch_size=100, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=100, \n",
    "                   validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficar el categorical crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predecir con el modelo\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7368238e-06, 9.1186339e-01, 8.8126816e-02],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [3.5548572e-21, 9.9920144e-04, 9.9900085e-01],\n",
       "       [2.3208834e-06, 8.6885190e-01, 1.3114583e-01],\n",
       "       [1.1196032e-05, 9.1531253e-01, 8.4676221e-02],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [3.8833734e-02, 9.5466727e-01, 6.4989068e-03],\n",
       "       [2.8118754e-11, 2.1400201e-01, 7.8599805e-01],\n",
       "       [9.5882456e-08, 7.1657598e-01, 2.8342399e-01],\n",
       "       [5.0784769e-03, 9.8194134e-01, 1.2980150e-02],\n",
       "       [3.6615466e-10, 3.4730062e-01, 6.5269941e-01],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [4.1216235e-06, 8.8782007e-01, 1.1217575e-01],\n",
       "       [3.8897360e-16, 1.6640177e-02, 9.8335981e-01],\n",
       "       [1.9156552e-03, 9.8035908e-01, 1.7725289e-02],\n",
       "       [3.0704650e-06, 8.7840122e-01, 1.2159572e-01],\n",
       "       [6.7659954e-16, 1.9006021e-02, 9.8099399e-01],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [1.6511985e-09, 4.4392070e-01, 5.5607933e-01],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [3.1626766e-15, 2.7483549e-02, 9.7251648e-01],\n",
       "       [9.2316137e-12, 1.7003833e-01, 8.2996172e-01],\n",
       "       [1.0190650e-12, 1.0525808e-01, 8.9474189e-01],\n",
       "       [1.6231404e-14, 4.0509280e-02, 9.5949078e-01],\n",
       "       [6.9673934e-16, 1.9140232e-02, 9.8085976e-01],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875367e-05],\n",
       "       [9.6089429e-01, 3.9071839e-02, 3.3875363e-05]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer ingenería en reversa, para dejar las predicciones en el formato original que teníamos de las \"Y\"\n",
    "uniques, ids = np.unique(Y, return_inverse=True)\n",
    "dummy_y = np_utils.to_categorical(ids, len(uniques))\n",
    "reverse = uniques[dummy_y.argmax(1)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reverse,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.967 \t 0.967 \t 0.967\n",
      "  Test \t 1.000 \t 1.000 \t 1.000\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "\n",
    "#métricas en el train\n",
    "Y_proba= model.predict(X_train)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_train = accuracy_score(y_train, Y_pred)\n",
    "prec_train = precision_score(y_train, Y_pred,average='weighted')\n",
    "reca_train = recall_score(y_train, Y_pred,average='weighted')\n",
    "\n",
    "\n",
    "#métricas en el test\n",
    "Y_proba= model.predict(X_test)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test, Y_pred)\n",
    "prec_test = precision_score(y_test, Y_pred,average='weighted')\n",
    "reca_test = recall_score(y_test, Y_pred,average='weighted')\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
